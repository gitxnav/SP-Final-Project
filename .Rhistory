}
print("Imputation Accuracy (Lower RMSE is better):")
print(imputation_accuracy %>% arrange(RMSE))
# Overall accuracy
overall_accuracy <- mean(imputation_accuracy$RMSE)
cat(sprintf("\nOverall Imputation Error (RMSE): %.4f\n", overall_accuracy))
# Compare distributions before and after imputation
cat("\n=== DISTRIBUTION PRESERVATION ANALYSIS ===\n")
# Select key variables for distribution comparison
key_vars <- c("age", "bp", "sc", "hemo", "htn", "dm")
# Create comparison plots
plot_list <- list()
for(var in key_vars) {
if(is.numeric(ckd_for_imputation[[var]])) {
# For numeric variables: density plot
df_compare <- data.frame(
Value = c(ckd_for_imputation[[var]], ckd_imputed[[var]]),
Dataset = rep(c("Original (with NA)", "kNN Imputed"),
each = nrow(ckd_for_imputation))
)
p <- ggplot(df_compare, aes(x = Value, fill = Dataset)) +
geom_density(alpha = 0.5) +
labs(title = paste("Distribution:", var),
x = var,
y = "Density") +
theme_minimal() +
theme(legend.position = "bottom")
} else {
# For categorical variables: bar plot
orig_counts <- table(ckd_for_imputation[[var]], useNA = "always")
imp_counts <- table(ckd_imputed[[var]])
df_compare <- data.frame(
Category = c(names(orig_counts), names(imp_counts)),
Count = c(as.numeric(orig_counts), as.numeric(imp_counts)),
Dataset = rep(c("Original", "Imputed"),
c(length(orig_counts), length(imp_counts)))
)
p <- ggplot(df_compare, aes(x = Category, y = Count, fill = Dataset)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = paste("Distribution:", var),
x = var,
y = "Count") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "bottom")
}
plot_list[[var]] <- p
}
# Arrange plots
grid.arrange(grobs = plot_list, ncol = 2,
top = "Distribution Comparison: Original vs kNN Imputed")
# Statistical comparison of distributions
cat("\nStatistical Comparison of Distributions (Kolmogorov-Smirnov Test):\n")
for(var in key_vars) {
if(is.numeric(ckd_for_imputation[[var]]) &&
is.numeric(ckd_imputed[[var]])) {
# Remove NAs for KS test
orig_clean <- na.omit(ckd_for_imputation[[var]])
imp_clean <- ckd_imputed[[var]]
if(length(orig_clean) > 0 && length(imp_clean) > 0) {
ks_test <- ks.test(orig_clean, imp_clean)
cat(sprintf("%s: D = %.3f, p = %.4f\n",
var, ks_test$statistic, ks_test$p.value))
}
}
}
cat("\n=== COMPARISON: kNN vs MICE IMPUTATION ===\n")
library(dplyr)
library(ggplot2)
# Compare missing values
cat("\nMissing Values Comparison:\n")
comparison <- data.frame(
Variable = names(ckd_for_imputation %>% select(-status)),
Original_NA = colSums(is.na(ckd_clean %>% select(-status))),
kNN_NA = colSums(is.na(ckd_imputed %>% select(-status))),
MICE_NA = colSums(is.na(ckd_mice_imputed %>% select(-status)))
)
print(comparison %>% filter(Original_NA > 0))
# Compare distributions for key variables
cat("\nDistribution Comparison (Key Variables):\n")
for(var in c("age", "sc", "hemo")) {
if(is.numeric(ckd_for_imputation[[var]])) {
# Calculate means
orig_mean <- mean(ckd_clean[[var]], na.rm = TRUE)
knn_mean <- mean(ckd_imputed[[var]], na.rm = TRUE)
mice_mean <- mean(ckd_mice_imputed[[var]], na.rm = TRUE)
cat(sprintf("\n%s:\n", var))
cat(sprintf("  Original (with NA): mean = %.2f\n", orig_mean))
cat(sprintf("  kNN imputed:        mean = %.2f (diff: %.2f)\n",
knn_mean, knn_mean - orig_mean))
cat(sprintf("  MICE imputed:       mean = %.2f (diff: %.2f)\n",
mice_mean, mice_mean - orig_mean))
}
}
# Create comparison plot
comparison_plot_data <- data.frame(
Method = rep(c("kNN", "MICE"), each = nrow(ckd_imputed)),
Age = c(ckd_imputed$age, ckd_mice_imputed$age),
Creatinine = c(ckd_imputed$sc, ckd_mice_imputed$sc),
Hemoglobin = c(ckd_imputed$hemo, ckd_mice_imputed$hemo)
)
p1 <- ggplot(comparison_plot_data, aes(x = Age, fill = Method)) +
geom_density(alpha = 0.5) +
labs(title = "Age Distribution: kNN vs MICE") +
theme_minimal()
p2 <- ggplot(comparison_plot_data, aes(x = Creatinine, fill = Method)) +
geom_density(alpha = 0.5) +
labs(title = "Creatinine Distribution: kNN vs MICE") +
theme_minimal()
p3 <- ggplot(comparison_plot_data, aes(x = Hemoglobin, fill = Method)) +
geom_density(alpha = 0.5) +
labs(title = "Hemoglobin Distribution: kNN vs MICE") +
theme_minimal()
grid.arrange(p1, p2, p3, ncol = 1,
top = "kNN vs MICE Imputation Comparison")
library(dplyr)
library(missForest)
# Start from the existing subset:
# nhanes_sub <- NHANES |> select(ID, Age, Gender, BMI, BPSysAve, Diabetes)
# 1) Keep only model-relevant columns (drop pure identifier)
# 2) Convert character variables to factors (missForest expects factors, not raw character)
# 3) Coerce to base data.frame to avoid tibble-related method dispatch issues
library(dplyr)
library(missForest)
# Prepare the data for missForest
# Select relevant predictor variables and the target 'status'
# Convert character/factor variables appropriately (missForest handles factors)
set.seed(17) # For reproducibility
mf_fit <- missForest(
ckd_for_imputation,
ntree   = 50,    # Number of trees in the random forest
maxiter = 5,      # Outer iterations
verbose = TRUE    # Set to TRUE to see progress
)
# Extract the imputed data and error metrics
ckd_missForest_imputed <- mf_fit$ximp
mf_oob_error <- mf_fit$OOBerror
# Check the Out-of-Bag (OOB) imputation error
print(paste("Normalized Root Mean Squared Error (NRMSE) for numeric variables:", mf_fit[["OOBerror"]][["NRMSE"]]))
print(paste("Proportion of Falsely Classified entries (PFC) for categorical variables:", mf_fit[["OOBerror"]][["PFC"]]))
# Verify no missing values remain
sum(is.na(ckd_missForest_imputed))
library(ggplot2)
library(patchwork)
# Function to plot distributions by class for a key variable
plot_dist_comparison <- function(orig_data,
knn_data,
mf_data,
var_name,
method_names = c("Original (with NAs)", "kNN Imputed", "missForest Imputed")) {
# Combine data for plotting
plot_data <- rbind(
data.frame(Value = orig_data[[var_name]], Status = orig_data$status, Method = method_names[1]),
data.frame(Value = knn_data[[var_name]], Status = knn_data$status, Method = method_names[2]),
data.frame(Value = mf_data[[var_name]], Status = mf_data$status, Method = method_names[3])
)
# Create density plot for numeric variables
p <- ggplot(plot_data, aes(x = Value, fill = Status)) +
geom_density(alpha = 0.6) +
facet_wrap(~ Method, ncol = 1) +
labs(title = paste("Distribution of", var_name, "by CKD Status"),
x = var_name,
y = "Density") +
theme_minimal() +
theme(legend.position = "bottom")
return(p)
}
# Example: Compare distributions for Serum Creatinine (sc)
# You will need your kNN-imputed dataset (ckd_knn_imputed) and missForest dataset
p_sc <- plot_dist_comparison(ckd_clean, ckd_knn_basic, ckd_missForest_imputed, "sc")
print(p_sc)
kidney_data <- ckd_clean
categorical_vars <- c("rbc", "pc", "pcc", "ba", "htn", "dm", "cad", "appet", "pe", "ane", "status")
kidney_data[categorical_vars] <- lapply(kidney_data[categorical_vars], as.factor)
# Convert ordinal/numeric-looking categorical variables to numeric
kidney_data$sg <- as.numeric(as.character(kidney_data$sg))
kidney_data$al <- as.numeric(as.character(kidney_data$al))
kidney_data$su <- as.numeric(as.character(kidney_data$su))
# Create binary target variable (1 for ckd, 0 for notckd)
kidney_data$target <- ifelse(kidney_data$status == "ckd", 1, 0)
# Remove original status column if needed
kidney_data$status <- NULL
# Select only numeric columns for correlation analysis
numeric_vars <- sapply(kidney_data, is.numeric)
numeric_data <- kidney_data[, numeric_vars]
# Calculate correlation matrix with target
cor_matrix <- cor(numeric_data, use = "complete.obs")
target_cor <- cor_matrix[,"target"]
# Sort correlations by absolute value
sorted_cor <- sort(abs(target_cor[names(target_cor) != "target"]), decreasing = TRUE)
# Print top correlated features
cat("Top features correlated with CKD:\n")
print(sorted_cor)
# Visualize correlations
library(corrplot)
corrplot(cor_matrix, method = "color", type = "upper",
tl.cex = 0.7, number.cex = 0.7)
# Select features above threshold (e.g., |cor| > 0.3)
threshold <- 0.3
important_numeric <- names(sorted_cor[abs(sorted_cor) > threshold])
cat("\nImportant numeric features (|cor| >", threshold, "):\n")
print(important_numeric)
# Function to calculate chi-square statistic between categorical variables
chi_square_test <- function(data, categorical_vars, target_var = "target") {
results <- data.frame()
for(var in categorical_vars) {
if(var != target_var) {
# Create contingency table
contingency_table <- table(data[[var]], data[[target_var]])
# Perform chi-square test
chi_test <- chisq.test(contingency_table)
# Calculate Cramér's V (effect size)
n <- sum(contingency_table)
k <- min(dim(contingency_table))
cramers_v <- sqrt(chi_test$statistic / (n * (k - 1)))
results <- rbind(results, data.frame(
Feature = var,
Chi_Square = chi_test$statistic,
p_value = chi_test$p.value,
Cramers_V = cramers_v
))
}
}
return(results[order(-results$Cramers_V), ])
}
# Test categorical variables (excluding target)
cat_vars <- categorical_vars[categorical_vars != "status"]
chi_results <- chi_square_test(kidney_data, cat_vars)
# Print results
print(chi_results)
# Select significant features (p < 0.05 and Cramér's V > 0.1)
significant_cat <- chi_results$Feature[chi_results$p_value < 0.05 &
chi_results$Cramers_V > 0.1]
cat("\nSignificant categorical features:\n")
print(significant_cat)
library(caret)
feature_selection_pipeline <- function(data, target_name = "target") {
# Separate numeric and categorical features
numeric_features <- names(data)[sapply(data, is.numeric)]
numeric_features <- numeric_features[numeric_features != target_name]
categorical_features <- names(data)[sapply(data, is.factor)]
categorical_features <- categorical_features[categorical_features != target_name]
# 1. Numeric features: Correlation with target
cor_values <- sapply(numeric_features, function(x) {
cor(data[[x]], data[[target_name]], use = "complete.obs")
})
# Select numeric features with |cor| > 0.25
selected_numeric <- names(cor_values)[abs(cor_values) > 0.25]
# 2. Categorical features: Chi-square test
chi_results <- data.frame()
for(cat_var in categorical_features) {
tbl <- table(data[[cat_var]], data[[target_name]])
chi_test <- chisq.test(tbl)
n <- sum(tbl)
k <- min(dim(tbl))
cramers_v <- sqrt(chi_test$statistic / (n * (k - 1)))
chi_results <- rbind(chi_results,
data.frame(Feature = cat_var,
p_value = chi_test$p.value,
Cramers_V = cramers_v))
}
# Select categorical features with p < 0.05 and Cramér's V > 0.15
selected_categorical <- chi_results$Feature[
chi_results$p_value < 0.05 & chi_results$Cramers_V > 0.15
]
# 3. Check for multicollinearity among selected numeric features
if(length(selected_numeric) > 1) {
numeric_cor <- cor(data[, selected_numeric], use = "complete.obs")
high_cor <- findCorrelation(numeric_cor, cutoff = 0.8)
if(length(high_cor) > 0) {
selected_numeric <- selected_numeric[-high_cor]
}
}
# Combine selected features
all_selected <- c(selected_numeric, as.character(selected_categorical))
cat("Selected Features:\n")
cat("-----------------\n")
cat("Numeric (", length(selected_numeric), "): ",
paste(selected_numeric, collapse = ", "), "\n\n")
cat("Categorical (", length(selected_categorical), "): ",
paste(selected_categorical, collapse = ", "), "\n")
return(list(
numeric = selected_numeric,
categorical = as.character(selected_categorical),
all = all_selected
))
}
# Run the pipeline
selected_features <- feature_selection_pipeline(kidney_data)
# Create dataset with only important features
important_vars <- selected_features$all
final_dataset <- kidney_data[, c(important_vars, "target")]
library(ggplot2)
# Create a feature importance plot
importance_df <- data.frame(
Feature = names(sorted_cor),
Correlation = as.numeric(sorted_cor),
Type = "Numeric"
)
# Add categorical features with Cramér's V
cat_importance <- data.frame(
Feature = chi_results$Feature,
Correlation = chi_results$Cramers_V,
Type = "Categorical"
)
importance_df <- rbind(importance_df, cat_importance)
# Plot
ggplot(importance_df, aes(x = reorder(Feature, Correlation),
y = Correlation, fill = Type)) +
geom_bar(stat = "identity") +
coord_flip() +
labs(title = "Feature Importance for CKD Prediction",
x = "Features",
y = "Correlation / Cramér's V") +
theme_minimal() +
geom_hline(yintercept = 0.2, linetype = "dashed", color = "red") +
annotate("text", x = 2, y = 0.22, label = "Threshold = 0.2",
color = "red", size = 3)
names(importance_df)
selected_cols <- c(importance_df %>% filter(Correlation >= 0.20) %>% pull(Feature))
selected_cols
typeof(selected_cols)
model_formula <- reformulate(selected_cols, response = "status")
model_formula
# Build logistic regression models on datasets from different imputation methods
model_original <- glm(model_formula,
data = ckd_clean, family = binomial, na.action = na.omit)
model_knn_basic <- glm(model_formula,
data = ckd_knn_basic, family = binomial)
model_knn_advanced <- glm(model_formula,
data = ckd_knn_advanced, family = binomial)
model_mice <- glm(model_formula,
data = ckd_mice_imputed, family = binomial)
model_missForest <- glm(model_formula,
data = ckd_missForest_imputed, family = binomial)
# Compare model coefficients
library(broom)
model_summary <- bind_rows(
tidy(model_original) %>% mutate(Method = "Original (CC)"),
tidy(model_knn_basic) %>% mutate(Method = "kNN_basic"),
tidy(model_knn_advanced) %>% mutate(Method = "kNN_Advanced"),
tidy(model_mice) %>% mutate(Method = "MICE"),
tidy(model_missForest) %>% mutate(Method = "missForest")
)
# Plot coefficient comparisons for key predictors
coef_plot <- model_summary %>%
filter(term %in% selected_cols) %>%
ggplot(aes(x = term, y = estimate, color = Method)) +
geom_point(position = position_dodge(width = 0.5)) +
geom_errorbar(aes(ymin = estimate - std.error, ymax = estimate + std.error),
width = 0.2, position = position_dodge(width = 0.5)) +
labs(title = "Comparison of Logistic Regression Coefficients",
subtitle = "After different imputation methods",
x = "Predictor",
y = "Coefficient Estimate") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(coef_plot)
model_knn_advanced
model_original
table(ckd_clean$status)
prop.table(table(ckd_clean$status))
table(na.omit(ckd_clean)$status)
prop.table(table(na.omit(ckd_clean)$status))
# Load required libraries
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
# Identify missing value positions in original data
# Get indices of all missing values
missing_indices <- which(is.na(ckd_clean), arr.ind = TRUE)
# Convert to a dataframe for easier handling
missing_df <- data.frame(
row = missing_indices[, 1],
column = colnames(ckd_clean)[missing_indices[, 2]],
variable = colnames(ckd_clean)[missing_indices[, 2]]
)
# Remove duplicates and sort
missing_df <- missing_df %>%
distinct(row, column, .keep_all = TRUE) %>%
arrange(row, column)
# Extract original patient characteristics (non-missing values) for context
extract_context <- function(row_idx, col_names) {
patient_data <- ckd_clean[row_idx, ]
# Get non-missing values for context
context_vars <- append(selected_cols, "status")
context_vals <- sapply(context_vars, function(v) {
if(v %in% names(patient_data)) {
val <- patient_data[[v]]
if(is.na(val)) "NA"
else as.character(val)
} else NA
})
return(context_vals)
}
# Get context for each missing value
context_data <- t(sapply(missing_df$row, extract_context,
col_names = names(ckd_clean)))
colnames(context_data) <- paste("Context", colnames(context_data))
# Extract imputed values from different methods
# Make sure you have these imputed datasets from previous code:
# ckd_knn_imputed (from kNN imputation)
# ckd_missForest_imputed (from missForest imputation)
# Function to extract values from imputed datasets
extract_imputed_values <- function(row_idx, col_name, dataset) {
if(col_name %in% colnames(dataset)) {
return(dataset[row_idx, col_name])
}
return(NA)
}
# Extract values for each missing position
missing_df$kNN_value <- mapply(extract_imputed_values,
missing_df$row, missing_df$column,
MoreArgs = list(dataset = ckd_knn_basic))
missing_df$missForest_value <- mapply(extract_imputed_values,
missing_df$row, missing_df$column,
MoreArgs = list(dataset = ckd_missForest_imputed))
# For MICE imputation (if you ran it earlier)
if(exists("ckd_mice_imputed")) {
missing_df$MICE_value <- mapply(extract_imputed_values,
missing_df$row, missing_df$column,
MoreArgs = list(dataset = ckd_mice_imputed))
}
# Combine with context
comparison_table <- cbind(missing_df, context_data)
# Reorder columns for better readability
comparison_table <- comparison_table %>%
select(row, variable, starts_with("Context"),
kNN_value, missForest_value, everything())
# Display first 20 rows of the comparison
head(comparison_table, 20) %>%
kable("html", caption = "Imputation Comparison at Missing Positions") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
setwd('/Volumes/HHD_iMac_Storage/URV/SCIENTIFIC_PROGRAMMING/FINAL/SP-Final-Project')
write_csv(ckd_knn_advanced, "data/processed/dataset_knn_imputed.csv",
progress = show_progress())
setwd('/Volumes/HHD_iMac_Storage/URV/SCIENTIFIC_PROGRAMMING/FINAL/SP-Final-Project')
write_csv(ckd_missForest_imputed, "data/processed/dataset_missForest_imputed.csv",
progress = show_progress())
# Load required libraries
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
# Identify missing value positions in original data
# Get indices of all missing values
missing_indices <- which(is.na(ckd_clean), arr.ind = TRUE)
# Convert to a dataframe for easier handling
missing_df <- data.frame(
row = missing_indices[, 1],
column = colnames(ckd_clean)[missing_indices[, 2]],
variable = colnames(ckd_clean)[missing_indices[, 2]]
)
# Remove duplicates and sort
missing_df <- missing_df %>%
distinct(row, column, .keep_all = TRUE) %>%
arrange(row, column)
# Extract original patient characteristics (non-missing values) for context
extract_context <- function(row_idx, col_names) {
patient_data <- ckd_clean[row_idx, ]
# Get non-missing values for context
context_vars <- append(selected_cols, "status")
context_vals <- sapply(context_vars, function(v) {
if(v %in% names(patient_data)) {
val <- patient_data[[v]]
if(is.na(val)) "NA"
else as.character(val)
} else NA
})
return(context_vals)
}
# Get context for each missing value
context_data <- t(sapply(missing_df$row, extract_context,
col_names = names(ckd_clean)))
colnames(context_data) <- paste("Context", colnames(context_data))
# Extract imputed values from different methods
# Make sure you have these imputed datasets from previous code:
# ckd_knn_imputed (from kNN imputation)
# ckd_missForest_imputed (from missForest imputation)
# Function to extract values from imputed datasets
extract_imputed_values <- function(row_idx, col_name, dataset) {
if(col_name %in% colnames(dataset)) {
return(dataset[row_idx, col_name])
}
return(NA)
}
# Extract values for each missing position
missing_df$kNN_value <- mapply(extract_imputed_values,
missing_df$row, missing_df$column,
MoreArgs = list(dataset = ckd_knn_basic))
missing_df$missForest_value <- mapply(extract_imputed_values,
missing_df$row, missing_df$column,
MoreArgs = list(dataset = ckd_missForest_imputed))
# For MICE imputation (if you ran it earlier)
if(exists("ckd_mice_imputed")) {
missing_df$MICE_value <- mapply(extract_imputed_values,
missing_df$row, missing_df$column,
MoreArgs = list(dataset = ckd_mice_imputed))
}
# Combine with context
comparison_table <- cbind(missing_df, context_data)
# Reorder columns for better readability
comparison_table <- comparison_table %>%
select(row, variable, starts_with("Context"),
kNN_value, missForest_value, everything())
# Display first 20 rows of the comparison
head(comparison_table, 20) %>%
kable("latex", caption = "Imputation Comparison at Missing Positions") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 10, fig.height = 6, format="latex")
