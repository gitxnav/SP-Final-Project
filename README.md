## Project Description - Chronic Kidney Disease (CKD)

This project uses the Chronic Kidney Disease (CKD) dataset to build a machine learning model that predicts whether a patient has CKD or not. The dataset contains clinical and laboratory features with missing values, which are cleaned and processed before training and evaluating the model. The final model is deployed as an API that takes patient data as input and returns a diagnostic prediction.

## Configuration of LOCAL environment
It is needed once the repo is cloned to create a python environment and to install the requirements file.

To install the python environment we need to execute:
```python

python -m venv .env

```

Once we have it, we need to activate it.

- If we are in Windows:

```python

.\.env\Scripts\activate

```

- If we are in Linux:

```
source .env/bin/activate
```

And once we have it activated, we need to download the packages that are in the `requirements.txt` file:

```python
pip install -r path/to/requirements.txt
```

**Note**. If we download news packages we need to include them in the requirements file. For doing that, once we installed the package, we need to update the `requirements.txt` file:
```python
pip freeze >> path/to/requirements.txt
```

## Configuration of DEVELOPMENT environment

The tree structure of Web Application

```{shell}
.
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ processed
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ckd_imputed.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ ckd_normalized.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset_knn_imputed.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset_mice_imputed.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ dataset_missForest_imputed.csv
â”‚Â Â  â”‚Â Â  â””â”€â”€ processed_dataset_ex.csv
â”‚Â Â  â”œâ”€â”€ raw
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ chronic_kidney_disease_info.txt
â”‚Â Â  â”‚Â Â  â””â”€â”€ chronic_kindey_disease.csv
â”‚Â Â  â”œâ”€â”€ sample_data.txt
â”‚Â Â  â””â”€â”€ samples
â”‚Â Â      â”œâ”€â”€ ckd_imputed.csv
â”‚Â Â      â””â”€â”€ ckd_normalized.csv
â”œâ”€â”€ docker
â”‚Â Â  â”œâ”€â”€ Dockerfile.backend
â”‚Â Â  â”œâ”€â”€ Dockerfile.frontend
â”‚Â Â  â”œâ”€â”€ Dockerfile.mlflow
â”‚Â Â  â”œâ”€â”€ run_app.sh
â”‚Â Â  â””â”€â”€ run_backend.sh
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_app.sh
â”œâ”€â”€ scripts
â”‚Â Â  â””â”€â”€ start.sh
â””â”€â”€ src
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ backend
    â”‚Â Â  â”œâ”€â”€ __init__.py
    â”‚Â Â  â”œâ”€â”€ api
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ main.py
    â”‚Â Â  â”‚Â Â  â””â”€â”€ routes
    â”‚Â Â  â”‚Â Â      â”œâ”€â”€ __init__.py
    â”‚Â Â  â”‚Â Â      â”œâ”€â”€ health.py
    â”‚Â Â  â”‚Â Â      â”œâ”€â”€ mlflow.py
    â”‚Â Â  â”‚Â Â      â”œâ”€â”€ prediction.py
    â”‚Â Â  â”‚Â Â      â””â”€â”€ training.py
    â”‚Â Â  â”œâ”€â”€ config
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ mlflow_config.py
    â”‚Â Â  â”‚Â Â  â””â”€â”€ settings.py
    â”‚Â Â  â”œâ”€â”€ core
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step01_data_loading.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step02_data_processing.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step03_feature_engineering.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step04_model_training.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step05_model_prediction.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step06_mlflow_config.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step07_mflow_training.py
    â”‚Â Â  â”‚Â Â  â””â”€â”€ step08_model_inference.py
    â”‚Â Â  â”œâ”€â”€ data
    â”‚Â Â  â”œâ”€â”€ figures
    â”‚Â Â  â”‚Â Â  â””â”€â”€ models
    â”‚Â Â  â”œâ”€â”€ main.py
    â”‚Â Â  â”œâ”€â”€ ml
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ model.py
    â”‚Â Â  â”‚Â Â  â””â”€â”€ train.py
    â”‚Â Â  â”œâ”€â”€ mlruns
    â”‚Â Â  â”œâ”€â”€ models
    â”‚Â Â  â””â”€â”€ reports
    â”‚Â Â      â””â”€â”€ models
    â”œâ”€â”€ frontend
    â”‚Â Â  â”œâ”€â”€ __init__.py
    â”‚Â Â  â”œâ”€â”€ data
    â”‚Â Â  â”œâ”€â”€ figures
    â”‚Â Â  â”‚Â Â  â””â”€â”€ models
    â”‚Â Â  â”‚Â Â      â”œâ”€â”€ gradient boosting_feature_importances.png
    â”‚Â Â  â”‚Â Â      â”œâ”€â”€ gradientboosting_imputed_confusion_matrix.png
    â”‚Â Â  â”‚Â Â      â”œâ”€â”€ knn_confusion_matrix.png
    â”‚Â Â  â”‚Â Â      â”œâ”€â”€ knn_optimization.png
    â”‚Â Â  â”‚Â Â      â””â”€â”€ svm_confusion_matrix.png
    â”‚Â Â  â”œâ”€â”€ internal
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ __init__.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ app.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step01_data_loading.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step02_data_processing.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step03_feature_engineering.py
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ step04_model_training.py
    â”‚Â Â  â”‚Â Â  â””â”€â”€ step05_model_prediction.py
    â”‚Â Â  â”œâ”€â”€ models
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ gb_imputed_model.pkl
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ knn_model.pkl
    â”‚Â Â  â”‚Â Â  â””â”€â”€ svm_model.pkl
    â”‚Â Â  â”œâ”€â”€ reports
    â”‚Â Â  â”‚Â Â  â”œâ”€â”€ feature_engineering_stats.json
    â”‚Â Â  â”‚Â Â  â””â”€â”€ models
    â”‚Â Â  â””â”€â”€ utils
    â”‚Â Â      â”œâ”€â”€ __init__.py
    â”‚Â Â      â””â”€â”€ api_client.py

```

##Â DEPLOYMENT Streamlit web application + MLflow framework + FastAPI

- release_version: v1.0-dev
- last_modified_date: 2026.01.22 

To deploy the main architecture by Docker it's important understand the two main parts:
- backend (FastAPI, the core) and MLflow framework
- frontend (Streamlit)

Now, follows these guidelines from your terminal to start the Docker containers.

From your workspace execute the `git clone`, if you haven't on your local environment. Otherwise, the first thing get a fetching and pull the last changes from main branch. It's mandatory to have the last version of the repository.

Important, if you have forked the repository from on your gitHub profile, first get the last changes from the original repository.

If you haven't the repository, just execute:

```{shell}
$ git clone https://github.com/gitxnav/SP-Final-Project
```

Check the status of the branch by:

```{shell}
$ git status
```

After this step, it's important having Docker Desktop or docker running. If you don't have Docker, it depends on your 
main Operating System. You could read about Docker following the installation manuals: https://docs.docker.com/engine/install/
 

The next step, to launch the applications execute this command first to allows the permissions to execute:

```{shell}
$ chmod +x start_services.sh stop_services.sh
```

Then, to execute the applications:

```{shell}
$ ./scripts/start_services.sh
```

During the next 5-10 minutes, you will show the docker-compose running for you. 
If there are no errors, the last part it's important to open the applications.

You will see something like:

```{shell}
 âœ” Network sp-final-project_ckd-network  Created                                                                                                                                                                                                    0.1s 
 âœ” Container ckd-mlflow                  Healthy                                                                                                                                                                                                    0.1s 
 âœ” Container ckd-backend                 Healthy                                                                                                                                                                                                    0.0s 
 âœ” Container ckd-frontend-internal       Started                                                                                                                                                                                                    0.0s 
â³ Waiting for services to be healthy...
ðŸ“Š Service Status:
NAME                    IMAGE                                COMMAND                  SERVICE             CREATED          STATUS                    PORTS
ckd-backend             sp-final-project-backend             "uvicorn api.main:apâ€¦"   backend             38 seconds ago   Up 21 seconds (healthy)   5050/tcp, 0.0.0.0:8000->8000/tcp
ckd-frontend-internal   sp-final-project-frontend-internal   "streamlit run interâ€¦"   frontend-internal   38 seconds ago   Up 10 seconds             0.0.0.0:8501->8501/tcp, 8502/tcp
ckd-mlflow              sp-final-project-mlflow              "mlflow server --bacâ€¦"   mlflow              38 seconds ago   Up 37 seconds (healthy)   0.0.0.0:5050->5050/tcp

âœ… System Started!

ðŸ“ Access Points:
   Internal Dashboard: http://localhost:8501
   User App:           http://localhost:8502
   Backend API:        http://localhost:8000/docs
   MLflow UI:          http://localhost:5050

ðŸ”§ Useful Commands:
   View logs:          docker-compose logs -f
   Stop system:        docker-compose down
   Restart backend:    docker-compose restart backend
```

That's it. Now you can open the application on your browser.

* Streamlit web application --> http://localhost:8501
* FastAPI --> http://localhost:8000 
* MLflow framework http://localhost:5050 

To stop the three docker containers or remove the containers on your local system, execute:

```{shell}
$ ./scripts/stop_services.sh
```

Finally, you could remove manually from Docker Desktop or by docker commands.

## Troubleshooting

It is normal if a Docker container does not work properly. This may depend on your operating system or on some dependencies running in the background. Please contact the developer if you experience any issues.
